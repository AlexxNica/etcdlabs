<md-sidenav-layout>
    <md-sidenav #sidenav [opened]="true" mode="side" class="doc-sidenav">
        <md-list dense>
            <a routerLink="/doc/{{docVersion}}">
                <h3 md-subheader>Getting Started ({{docVersion}})</h3>
            </a>
            <md-list-item *ngFor="let item of getStartedItems">
                <a routerLink="{{item.url}}" class="{{item.htmlClass}}">{{item.title}}</a>
            </md-list-item>

            <md-divider></md-divider>
            <h3 md-subheader>Operation Guides</h3>
            <md-list-item *ngFor="let item of operationItems">
                <a routerLink="{{item.url}}" class="{{item.htmlClass}}">{{item.title}}</a>
            </md-list-item>
        </md-list>
    </md-sidenav>

    <div class="doc-group">
        <router-outlet></router-outlet>

        <h4>Upgrade etcd</h4>
        <p class="narrow-paragraph">
            In general, upgrading from etcd v3.0.x to higher can be a zero-downtime, rolling upgrade. Just stop one node at a time, and restart etcd process with new executable binary file and same configuration.
        </p>

        <br>
        <h5>Upgrade Checklists</h5>
        <p class="narrow-paragraph">
            To ensure a smooth rolling upgrade, the running cluster must be healthy. You can check the health of the cluster by using the <span class="code-light-snippet">etcdctl endpoint health</span> command.
        </p>
        <p class="narrow-paragraph">
            Before upgrading etcd, always test the services relying on etcd in a staging environment before deploying the upgrade to the production environment.
        </p>
        <p class="narrow-paragraph">
            Before beginning, backup the etcd data with <span class="code-light-snippet">etcdctl snapshot</span> command. Should something go wrong with the upgrade, it is possible to use this backup to downgrade back to existing etcd version.
        </p>
        <p class="narrow-paragraph">
            While upgrading, an etcd cluster supports mixed versions of etcd members, and operates with the protocol of the lowest common version. The cluster is only considered upgraded once all of its members are upgraded to newer version. Internally, etcd members
            negotiate with each other to determine the overall cluster version, which controls the reported version and the supported features.
        </p>
        <p class="narrow-paragraph">
            It might take up to 2 minutes for the newly upgraded member to catch up with the existing cluster when the total data size is larger than 50MB. Check the size of a recent snapshot to estimate the total data size. In other words, it is safest to wait for
            2 minutes between upgrading each member.
        </p>
        <p class="narrow-paragraph">
            For a much larger total data size, 100MB or more , this one-time process might take even more time. Administrators of very large etcd clusters of this magnitude can feel free to contact the <a href="https://groups.google.com/forum/#!forum/etcd-dev"
                target="_blank" class="normal-link">etcd team</a> before upgrading, and weâ€™ll be happy to provide advice on the procedure.
        </p>

        <br>
        <h5>Upgrade Procedure</h5>
        <p class="narrow-paragraph">
            Check upgrade requirements. And check cluster health.
        </p>
        <div class="osx-window">
            <div class="window">
                <div class="titlebar">
                    <div class="buttons">
                        <div class="closebtn"><span><strong></strong></span></div>
                        <div class="minimize"><span><strong></strong></span></div>
                        <div class="zoom"><span><strong></strong></span></div>
                    </div><span class="title-bar-text">terminal</span></div>
                <div class="content">
                    <pre class="osx-terminal-contents">$ ETCDCTL_API=3 etcdctl endpoint health --endpoints=localhost:2379,localhost:22379,localhost:32379

localhost:2379 is healthy: successfully committed proposal: took = 1.45438ms
localhost:22379 is healthy: successfully committed proposal: took = 1.161324ms
localhost:32379 is healthy: successfully committed proposal: took = 1.41825ms

$ curl http://localhost:2379/version
"etcdserver":"3.1.0","etcdcluster":"3.1.0"
</pre>
                </div>
            </div>
        </div>
        <p class="narrow-paragraph">
            Stop the existing etcd process. When each etcd process is stopped, expected errors will be logged by other cluster members. This is normal since a cluster member connection has been (temporarily) broken:
        </p>
        <div class="osx-window">
            <div class="window">
                <div class="titlebar">
                    <div class="buttons">
                        <div class="closebtn"><span><strong></strong></span></div>
                        <div class="minimize"><span><strong></strong></span></div>
                        <div class="zoom"><span><strong></strong></span></div>
                    </div><span class="title-bar-text">terminal</span></div>
                <div class="content">
                    <pre class="osx-terminal-contents">rafthttp: lost the TCP streaming connection with peer 91bc3c398fb3c146 (stream MsgApp v2 reader)
rafthttp: failed to read 91bc3c398fb3c146 on stream MsgApp v2 (unexpected EOF)
rafthttp: peer 91bc3c398fb3c146 became inactive
</pre>
                </div>
            </div>
        </div>
        <p class="narrow-paragraph">
            Drop-in new etcd binary and start the new etcd process with the same configuration. The new etcd will publish its information to the cluster. Repeat the same steps for all other members.
        </p>

        <br>
        <h5>Upgrade from v2.3.x</h5>
        <p class="narrow-paragraph">
            Please follow instructions <a href="https://github.com/coreos/etcd/blob/master/Documentation/upgrades/upgrade_3_0.md" target="_blank" class="normal-link">here</a>.
        </p>

    </div>
</md-sidenav-layout>